{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Forecast con Moirai-MoE-Base (Salesforce/moirai-moe-1.0-R-base) + Yahoo Finance (descarga por ventanas)\n",
        "\n",
        "**Notebook generado automáticamente.**\n",
        "\n",
        "Este cuaderno descarga datos de Yahoo Finance por *ventanas* de tiempo (robusto a índices con zonas horarias y posibles columnas MultiIndex), normaliza columnas OHLCV, y realiza *forecasting probabilístico* con **Moirai-MoE-Base** usando **Uni2TS + GluonTS**. Genera un CSV y una imagen con el pronóstico.\n",
        "\n",
        "### Requisitos sugeridos (entorno estable)\n",
        "\n",
        "```bash\n",
        "pip install \"numpy==1.26.4\" \"pandas==2.1.4\"\n",
        "pip install \"torch==2.3.1\" --index-url https://download.pytorch.org/whl/cpu\n",
        "pip install \"uni2ts==1.2.0\" \"gluonts==0.14.3\" yfinance matplotlib huggingface_hub tqdm\n",
        "```\n",
        "\n",
        "> Puedes ajustar a GPU instalando el build de PyTorch con CUDA que corresponda a tu sistema. En Windows, si usas `pip`, sigue la guía de PyTorch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.status.busy": true
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Administrator\\Desktop\\PROYECTOS\\FORECASTING\\venv_moirai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# Imports básicos y configuración general\n",
        "import warnings, re, time\n",
        "from pathlib import Path\n",
        "from typing import Optional, Dict, List\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from gluonts.dataset.common import ListDataset\n",
        "from uni2ts.model.moirai_moe import MoiraiMoEForecast, MoiraiMoEModule\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams['figure.dpi'] = 120\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utilidades de fechas y frecuencia\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _allowed_days_and_step(interval: str):\n",
        "    interval = interval.lower()\n",
        "    if interval in (\"1m\", \"2m\"): return 30, 5\n",
        "    if interval in (\"5m\", \"15m\", \"30m\"): return 60, 10\n",
        "    if interval in (\"60m\", \"1h\", \"90m\"): return 730, 60\n",
        "    if interval in (\"1d\", \"5d\", \"1wk\"): return 10000, 365 * 2\n",
        "    return 3650, 180\n",
        "\n",
        "def _to_pd_freq(interval: str) -> str:\n",
        "    m = interval.lower()\n",
        "    if m.endswith(\"m\"): return f\"{m[:-1]}min\"\n",
        "    if m.endswith(\"h\"): return f\"{m[:-1]}H\"\n",
        "    if m.endswith(\"d\"): return \"D\"\n",
        "    if m.endswith(\"wk\"): return \"W\"\n",
        "    return \"D\"\n",
        "\n",
        "def _to_utc(ts) -> pd.Timestamp:\n",
        "    ts = pd.Timestamp(ts)\n",
        "    if ts.tzinfo is None: return ts.tz_localize(\"UTC\")\n",
        "    return ts.tz_convert(\"UTC\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Normalización robusta de columnas (maneja MultiIndex, `adj_close` → `close`, tokens como `AAPL_Close`, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "_OHLCV_KEYS = (\"open\", \"high\", \"low\", \"close\", \"adj_close\", \"volume\")\n",
        "\n",
        "def _flatten_columns(df: pd.DataFrame) -> List[str]:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        cols = [\n",
        "            \"_\".join([str(x) for x in tup if x is not None and f\"{x}\".strip() != \"\"]).strip()\n",
        "            for tup in df.columns.values\n",
        "        ]\n",
        "    else:\n",
        "        cols = [str(c) for c in df.columns]\n",
        "    return cols\n",
        "\n",
        "def _normalize_ohlcv_columns(df: pd.DataFrame, debug: bool=False, tag: str=\"\") -> pd.DataFrame:\n",
        "    if df is None or df.empty:\n",
        "        return df\n",
        "\n",
        "    # 1) Aplanar y asignar\n",
        "    flat_cols = _flatten_columns(df)\n",
        "    df = df.copy()\n",
        "    df.columns = flat_cols\n",
        "\n",
        "    # 2) Normalizar nombres básicos y asignar (minúsculas, espacios->'_')\n",
        "    norm_cols = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
        "    df.columns = norm_cols\n",
        "\n",
        "    # 3) Tokenizar y agrupar candidatos por clave\n",
        "    buckets: Dict[str, List[str]] = {k: [] for k in _OHLCV_KEYS}\n",
        "    for col in df.columns:\n",
        "        tokens = re.split(r\"[^a-z0-9]+\", col)\n",
        "        ts = [t for t in tokens if t]\n",
        "        s = set(ts)\n",
        "        if \"open\" in s: buckets[\"open\"].append(col)\n",
        "        if \"high\" in s: buckets[\"high\"].append(col)\n",
        "        if \"low\"  in s: buckets[\"low\"].append(col)\n",
        "        if \"close\" in s and \"adj\" not in s: buckets[\"close\"].append(col)\n",
        "        if \"close\" in s and \"adj\" in s: buckets[\"adj_close\"].append(col)\n",
        "        if \"volume\" in s: buckets[\"volume\"].append(col)\n",
        "\n",
        "    # Intento de coincidencia exacta si algún bucket está vacío\n",
        "    for col in df.columns:\n",
        "        if col in _OHLCV_KEYS and col not in sum(buckets.values(), []):\n",
        "            buckets[col].append(col)\n",
        "\n",
        "    # 4) Elegir el primer candidato por clave\n",
        "    picks: Dict[str, str] = {}\n",
        "    for k in _OHLCV_KEYS:\n",
        "        if buckets[k]:\n",
        "            picks[k] = buckets[k][0]\n",
        "\n",
        "    # 5) Si no hay 'close' pero hay 'adj_close', usarla como close\n",
        "    if \"close\" not in picks and \"adj_close\" in picks:\n",
        "        picks[\"close\"] = picks[\"adj_close\"]\n",
        "\n",
        "    if debug:\n",
        "        print(f\"[normalize{(':'+tag) if tag else ''}] flat_cols={flat_cols}\")\n",
        "        print(f\"[normalize{(':'+tag) if tag else ''}] norm_cols={norm_cols}\")\n",
        "        print(f\"[normalize{(':'+tag) if tag else ''}] picks={picks}\")\n",
        "\n",
        "    keep_order = [k for k in [\"open\",\"high\",\"low\",\"close\",\"volume\"] if k in picks]\n",
        "    if not keep_order:\n",
        "        return df\n",
        "\n",
        "    out = pd.DataFrame(index=df.index.copy())\n",
        "    for k in keep_order:\n",
        "        out[k] = pd.to_numeric(df[picks[k]], errors=\"coerce\")\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Descarga ventana-a-ventana (Yahoo Finance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_yf_windowed(\n",
        "    ticker: str, interval: str, start=None, end=None,\n",
        "    want_max=True, tz=\"UTC\", max_retries=3, sleep=1.0, debug: bool=False\n",
        ") -> pd.DataFrame:\n",
        "    allowed_days, step_days = _allowed_days_and_step(interval)\n",
        "\n",
        "    # --- Fechas robustas ---\n",
        "    if end is None: end = pd.Timestamp.now(tz=\"UTC\")\n",
        "    else: end = _to_utc(end)\n",
        "\n",
        "    if start is None:\n",
        "        if want_max: start = end - pd.Timedelta(days=allowed_days * 50)\n",
        "        else: start = end - pd.Timedelta(days=allowed_days)\n",
        "    else:\n",
        "        start = _to_utc(start)\n",
        "\n",
        "    dfs = []\n",
        "    cur = start\n",
        "    pbar = tqdm(total=None, desc=f\"Descargando {ticker} {interval} por ventanas\")\n",
        "\n",
        "    while cur < end:\n",
        "        win_end = min(cur + pd.Timedelta(days=step_days), end)\n",
        "        retries = 0\n",
        "        got = None\n",
        "        while retries <= max_retries:\n",
        "            try:\n",
        "                df = yf.download(\n",
        "                    ticker, interval=interval,\n",
        "                    start=cur, end=win_end,\n",
        "                    progress=False, auto_adjust=False, prepost=False, threads=True,\n",
        "                    group_by=\"column\"  # intenta evitar MultiIndex por ticker\n",
        "                )\n",
        "                if isinstance(df, pd.DataFrame) and not df.empty:\n",
        "                    got = df.copy()\n",
        "                break\n",
        "            except Exception:\n",
        "                retries += 1\n",
        "                time.sleep(sleep * (2 ** retries))\n",
        "        if got is not None and not got.empty:\n",
        "            got = _normalize_ohlcv_columns(got, debug=debug, tag=f\"{cur.date()}->{win_end.date()}\")\n",
        "            if debug:\n",
        "                print(f\"[window] {cur} -> {win_end} shape={got.shape} cols={list(got.columns)}\")\n",
        "            dfs.append(got)\n",
        "        cur = win_end\n",
        "        pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    if len(dfs) == 0:\n",
        "        raise RuntimeError(\"No se descargaron datos (posible combinación inválida ticker/intervalo).\")\n",
        "\n",
        "    data = pd.concat(dfs).sort_index()\n",
        "    data = data.loc[~data.index.duplicated(keep=\"last\")]\n",
        "\n",
        "    # normalización final por seguridad\n",
        "    data = _normalize_ohlcv_columns(data, debug=debug, tag=\"final\")\n",
        "\n",
        "    # Índice tz-aware -> UTC -> tz destino\n",
        "    if data.index.tz is None: data.index = data.index.tz_localize(\"UTC\")\n",
        "    else: data.index = data.index.tz_convert(\"UTC\")\n",
        "    data = data.tz_convert(tz)\n",
        "\n",
        "    # astype seguro y dropna all\n",
        "    for c in data.columns:\n",
        "        data[c] = pd.to_numeric(data[c], errors=\"coerce\")\n",
        "    data = data.dropna(how=\"all\")\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helpers de zona horaria y *plotting*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _to_naive_utc(idx: pd.DatetimeIndex) -> pd.DatetimeIndex:\n",
        "    if idx.tz is None: idx = idx.tz_localize(\"UTC\")\n",
        "    else: idx = idx.tz_convert(\"UTC\")\n",
        "    return idx.tz_localize(None)\n",
        "\n",
        "def make_plot(history: pd.Series, pred_index: pd.DatetimeIndex, mean: np.ndarray,\n",
        "              p10: Optional[np.ndarray] = None, p90: Optional[np.ndarray] = None,\n",
        "              title: str = \"Forecast con Moirai-MoE\", out_png: Optional[Path] = None) -> Path:\n",
        "    plt.figure(figsize=(11, 5))\n",
        "    plt.plot(history.index, history.values, label=\"Histórico (contexto)\")\n",
        "    plt.plot(pred_index, mean, label=\"Pronóstico (media)\")\n",
        "    if p10 is not None and p90 is not None:\n",
        "        plt.fill_between(pred_index, p10, p90, alpha=0.2, label=\"PI 80%\")\n",
        "    plt.title(title); plt.xlabel(\"Tiempo\"); plt.ylabel(\"Valor\"); plt.legend(); plt.tight_layout()\n",
        "    out_png = out_png or Path(\"forecast_plot.png\"); plt.savefig(out_png, dpi=150); plt.close()\n",
        "    return out_png\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Función principal de *forecast*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_forecast(\n",
        "    ticker: str,\n",
        "    interval: str,\n",
        "    start: Optional[str],\n",
        "    end: Optional[str],\n",
        "    pred_len: int,\n",
        "    ctx_len: int,\n",
        "    patch_size: int,\n",
        "    num_samples: int,\n",
        "    batch_size: int,\n",
        "    column: str,\n",
        "    out_dir: Path,\n",
        "    tz_out: str,\n",
        "    debug: bool=False\n",
        "):\n",
        "    out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 1) Descarga\n",
        "    raw = download_yf_windowed(\n",
        "        ticker=ticker, interval=interval, start=start, end=end,\n",
        "        want_max=True, tz=tz_out, max_retries=3, sleep=1.0, debug=debug\n",
        "    )\n",
        "    if raw is None or raw.empty:\n",
        "        raise RuntimeError(\"No se obtuvieron datos desde Yahoo. Revisa ticker/intervalo/fechas.\")\n",
        "\n",
        "    if debug:\n",
        "        print(f\"[raw] shape={raw.shape} cols={list(raw.columns)} idx=[{raw.index[0]} -> {raw.index[-1]}]\")\n",
        "\n",
        "    # 2) Columna objetivo\n",
        "    col_key = column.strip().lower().replace(\" \", \"_\")\n",
        "    if col_key not in raw.columns:\n",
        "        raise ValueError(f\"La columna '{column}' no existe. Disponibles: {list(raw.columns)}\")\n",
        "    s = raw[col_key].copy()  # Serie con tz\n",
        "\n",
        "    # 3) Frecuencia uniforme\n",
        "    freq = _to_pd_freq(interval)\n",
        "    full_idx = pd.date_range(start=s.index[0], end=s.index[-1], freq=freq, tz=s.index.tz)\n",
        "    s = s.reindex(full_idx).ffill().bfill()\n",
        "\n",
        "    # 4) Contexto\n",
        "    if ctx_len > 0 and len(s) > ctx_len: s_ctx = s.iloc[-ctx_len:].copy()\n",
        "    else: s_ctx = s.copy()\n",
        "\n",
        "    if len(s_ctx) < max(8, pred_len + 1):\n",
        "        raise RuntimeError(f\"Pocos datos ({len(s_ctx)}) para {ticker} en {interval}. Ajusta --start/--ctx_len.\")\n",
        "\n",
        "    # 5) Dataset GluonTS (naive UTC + 1D float32)\n",
        "    start_naive_utc = _to_naive_utc(s_ctx.index)[0]\n",
        "    target_1d = s_ctx.to_numpy(dtype=\"float32\")\n",
        "    input_ds = ListDataset([{\"start\": start_naive_utc, \"target\": target_1d}], freq=freq)\n",
        "\n",
        "    # 6) Modelo Moirai-MoE\n",
        "    module = MoiraiMoEModule.from_pretrained(\"Salesforce/moirai-moe-1.0-R-base\")\n",
        "    model = MoiraiMoEForecast(\n",
        "        module=module,\n",
        "        prediction_length=pred_len,\n",
        "        context_length=len(s_ctx),\n",
        "        patch_size=patch_size,\n",
        "        num_samples=num_samples,\n",
        "        target_dim=1,\n",
        "        feat_dynamic_real_dim=0,\n",
        "        past_feat_dynamic_real_dim=0,\n",
        "    )\n",
        "    predictor = model.create_predictor(batch_size=batch_size)\n",
        "\n",
        "    # 7) Predicción\n",
        "    forecasts = predictor.predict(input_ds)\n",
        "    forecast = next(iter(forecasts))\n",
        "\n",
        "    # 8) Índice futuro y cuantiles\n",
        "    start_pred = pd.Timestamp(getattr(forecast.start_date, \"to_timestamp\", lambda: forecast.start_date)())\n",
        "    pred_index_naive = pd.date_range(start=start_pred, periods=pred_len, freq=freq)\n",
        "    pred_index = pred_index_naive.tz_localize(\"UTC\").tz_convert(s_ctx.index.tz)\n",
        "\n",
        "    mean = forecast.mean\n",
        "    try:\n",
        "        p10 = forecast.quantile(0.1); p90 = forecast.quantile(0.9)\n",
        "    except Exception:\n",
        "        p10 = forecast.quantile(\"0.1\"); p90 = forecast.quantile(\"0.9\")\n",
        "\n",
        "    # 9) Guardar\n",
        "    out_csv = out_dir / \"forecast.csv\"\n",
        "    pd.DataFrame({\"timestamp\": pred_index, \"mean\": mean, \"p10\": p10, \"p90\": p90}) \\\n",
        "        .set_index(\"timestamp\").to_csv(out_csv, float_format=\"%.6f\")\n",
        "\n",
        "    title = f\"{ticker} {interval} | Moirai-MoE-Base (pred_len={pred_len}, ctx_len={len(s_ctx)})\"\n",
        "    out_png = make_plot(s_ctx, pred_index, mean, p10, p90, title=title, out_png=out_dir / \"forecast_plot.png\")\n",
        "\n",
        "    # 10) Resumen\n",
        "    print(\"[OK] Pronóstico generado\")\n",
        "    print(f\"  - Ticker:        {ticker}\")\n",
        "    print(f\"  - Intervalo:     {interval}  (freq={freq})\")\n",
        "    print(f\"  - TZ salida:     {tz_out}\")\n",
        "    print(f\"  - Contexto:      {len(s_ctx)} muestras\")\n",
        "    print(f\"  - Predicción:    {pred_len} pasos\")\n",
        "    print(f\"  - Patch size:    {patch_size}\")\n",
        "    print(f\"  - Muestras:      {num_samples}\")\n",
        "    print(f\"  - CSV:           {out_csv.resolve()}\")\n",
        "    print(f\"  - Gráfico PNG:   {out_png.resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parámetros (edita y ejecuta)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "TICKER   = \"BTC-USD\"          # Ej.: \"AAPL\", \"BTC-USD\", \"^GSPC\"\n",
        "INTERVAL = \"1d\"            # 1m 2m 5m 15m 30m 60m 90m 1h 1d 5d 1wk 1mo 3mo\n",
        "START    = \"2015-01-01\"    # o None\n",
        "END      = None            # o \"YYYY-MM-DD\"\n",
        "PRED_LEN = 30\n",
        "CTX_LEN  = 10000\n",
        "PATCH    = 16\n",
        "SAMPLES  = 100\n",
        "BATCH    = 32\n",
        "COLUMN   = \"close\"         # close/open/high/low/volume\n",
        "OUT_DIR  = Path(\"outputs_moirai_moe\")\n",
        "TZ_OUT   = \"America/Mexico_City\"\n",
        "DEBUG    = False           # True para imprimir detalles de normalización/ventanas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ejecutar pronóstico\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Descargando BTC-USD 1d por ventanas: 6it [00:00, 25.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Pronóstico generado\n",
            "  - Ticker:        BTC-USD\n",
            "  - Intervalo:     1d  (freq=D)\n",
            "  - TZ salida:     America/Mexico_City\n",
            "  - Contexto:      3905 muestras\n",
            "  - Predicción:    30 pasos\n",
            "  - Patch size:    16\n",
            "  - Muestras:      100\n",
            "  - CSV:           C:\\Users\\Administrator\\Desktop\\PROYECTOS\\FORECASTING\\FORECASTING\\outputs_moirai_moe\\forecast.csv\n",
            "  - Gráfico PNG:   C:\\Users\\Administrator\\Desktop\\PROYECTOS\\FORECASTING\\FORECASTING\\outputs_moirai_moe\\forecast_plot.png\n"
          ]
        }
      ],
      "source": [
        "run_forecast(\n",
        "    ticker=TICKER,\n",
        "    interval=INTERVAL,\n",
        "    start=START,\n",
        "    end=END,\n",
        "    pred_len=PRED_LEN,\n",
        "    ctx_len=CTX_LEN,\n",
        "    patch_size=PATCH,\n",
        "    num_samples=SAMPLES,\n",
        "    batch_size=BATCH,\n",
        "    column=COLUMN,\n",
        "    out_dir=OUT_DIR,\n",
        "    tz_out=TZ_OUT,\n",
        "    debug=DEBUG,\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv_moirai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
